{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "random_gen = np.random.RandomState(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры тестового автокодировщика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs = 10\n",
    "num_outputs = 10\n",
    "num_hidden_units = 2\n",
    "\n",
    "num_objects = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция потерь и ее градиент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_function(autoencoder, weights, inputs):\n",
    "    autoencoder.net.set_weights(weights)\n",
    "    outputs = autoencoder.net.compute_outputs(inputs)\n",
    "    loss_value = 0.5 * np.sum((inputs - outputs) ** 2, axis=0).mean()\n",
    "    \n",
    "    return loss_value\n",
    "\n",
    "def loss_function_grad(autoencoder, weights, inputs):\n",
    "    autoencoder.net.set_weights(weights)\n",
    "    \n",
    "    _ = autoencoder.net.compute_outputs(inputs)\n",
    "    _, grad = autoencoder.compute_loss(inputs)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def GN_loss_function(autoencoder, weights, inputs, direction):\n",
    "    autoencoder.net.set_weights(weights)    \n",
    "    outputs = autoencoder.net.compute_outputs(inputs)\n",
    "    \n",
    "    return np.sum(outputs * direction, axis=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание автокодировщика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from layers import FCLayer\n",
    "from activations import SigmoidActivationFunction, LinearActivationFunction\n",
    "from autoencoder import Autoencoder\n",
    "\n",
    "hidden_layer = FCLayer(shape=(num_inputs, num_hidden_units), \n",
    "                       afun=SigmoidActivationFunction(), \n",
    "                       use_bias=True)\n",
    "\n",
    "output_layer = FCLayer(shape=(num_hidden_units, num_outputs),\n",
    "                       afun=LinearActivationFunction(),\n",
    "                       use_bias=True)\n",
    "\n",
    "autoencoder = Autoencoder([hidden_layer, output_layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация весов сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_1 = random_gen.uniform(low=-1 / np.sqrt(num_inputs), \n",
    "                               high=1 / np.sqrt(num_inputs), \n",
    "                               size=(num_hidden_units, num_inputs))\n",
    "weights_1 = np.c_[weights_1, np.zeros(num_hidden_units)]\n",
    "\n",
    "weights_2 = random_gen.uniform(low=-1 / np.sqrt(num_hidden_units), \n",
    "                               high=1 / np.sqrt(num_hidden_units), \n",
    "                               size=(num_outputs, num_hidden_units))\n",
    "weights_2 = np.c_[weights_2, np.zeros(num_outputs)]\n",
    "\n",
    "weights = np.r_[weights_1.ravel(), weights_2.ravel()]\n",
    "\n",
    "autoencoder.net.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем тестовый мини-батч"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = random_gen.normal(size=(num_inputs, num_objects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка корректности вычисления градиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from approx_gradient import compute_approx_grad\n",
    "\n",
    "_, exact_grad = autoencoder.compute_loss(inputs)\n",
    "\n",
    "num_params = autoencoder.net.params_number\n",
    "\n",
    "direction = np.zeros_like(weights)\n",
    "approx_grad = np.zeros_like(weights)\n",
    "\n",
    "for i in range(num_params):\n",
    "    direction[:] = 0\n",
    "    direction[i] = 1\n",
    "\n",
    "    approx_grad[i] = compute_approx_grad(lambda x: loss_function(autoencoder, x, inputs), weights, direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Порядок разницы между точным градиентом и его аппроксимацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_absolute_diff = np.abs(exact_grad - approx_grad).max()\n",
    "\n",
    "np.floor(np.log10(max_absolute_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка корректности вычисления гессиана на вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from approx_gradient import compute_approx_grad\n",
    "\n",
    "num_test_direction = 5\n",
    "num_params = autoencoder.net.params_number\n",
    "\n",
    "direction_pool = [random_gen.normal(size=num_params) for _ in range(num_test_direction)]\n",
    "\n",
    "exact_Hps = [autoencoder.compute_hessvec(direction) \n",
    "             for direction in direction_pool]\n",
    "\n",
    "approx_Hps = [compute_approx_grad(lambda x: loss_function_grad(autoencoder, x, inputs), weights, direction) \n",
    "              for direction in direction_pool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Порядки разницы между точным произведением гессиана на вектор и его аппроксимацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8., -8., -8., -8., -8.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_absolute_diffs = [np.abs(exact_Hp - approx_Hp).max() for exact_Hp, approx_Hp in zip(exact_Hps, approx_Hps)]\n",
    "np.floor(np.log10(max_absolute_diffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Проверка корректности вычисления градиента функции потерь для гаусс-ньютоновской аппрокимации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from approx_gradient import compute_approx_grad\n",
    "\n",
    "# A product of jaccobian and some vector\n",
    "qs = random_gen.normal(size=(num_outputs, num_objects))\n",
    "\n",
    "exact_grad = autoencoder.net.compute_loss_grad(qs)\n",
    "\n",
    "direction = np.zeros_like(weights)\n",
    "approx_grad = np.zeros_like(weights)\n",
    "\n",
    "for i in range(num_params):\n",
    "    direction[:] = 0\n",
    "    direction[i] = 1\n",
    "\n",
    "    approx_grad[i] = compute_approx_grad(lambda x: GN_loss_function(autoencoder, x, inputs, qs), weights, direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Порядок разницы между точным градиентом и его аппроксимацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_absolute_diff = np.abs(exact_grad - approx_grad).max()\n",
    "\n",
    "np.floor(np.log10(max_absolute_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}